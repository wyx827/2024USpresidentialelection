---
title: "Predicting Kamala Harris's Victory in the 2024 US Election"
subtitle: "An Investigation into Poll Data Using Multiple Linear Regression"
author: 
  - Xuanle Zhou
  - Yongqi Liu
  - Yuxuan Wei
thanks: "Code and data are available at: https://github.com/wyx827/2024USpresidentialelection.git"
date: today
date-format: long
toc: true
abstract: "The study predicting the 2024 U.S. presidential election is important as it provides the predicted outcomes for the US election. Analysis is based on state-by-state electoral votes, and these outcomes can influence campaign strategies and shape public discourse. The result indicates Kamala Harris will win by over 270 votes in this election cycle."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

# Install the required packages
#install.packages(c("tidyverse", "ggplot2", "rstanarm", "knitr", "usmap", "corrplot", "arrow"))
library(tidyverse)
library(ggplot2)
library(rstanarm)
library(knitr)
library(usmap)
library(corrplot)
library(arrow)
analysis_data <- read_csv(here::here("data/02-analysis_data/cleaned_US_voting.csv"))
```

# Introduction

The 2024 U.S. Presidential Election is set to unfold in a climate of heightened political polarization, economic challenges, and demographic shifts, making it a pivotal event in shaping America's future. Predicting the outcome of this election is crucial for gaining insights into potential changes in political leadership and policy directions. Polling data has traditionally served as a primary tool for gauging voter sentiment; however, recent election cycles have exposed limitations in polling accuracy due to biases, non-response issues, and variations in poll quality. To address these challenges, this study proposes a model that incorporates these factors to enhance the reliability of election forecasts.

This paper develops a prediction model aimed at forecasting the electoral outcomes between Kamala Harris and Donald Trump in the 2024 election. Using a multiple linear regression framework, we analyze aggregated polling data across U.S. states, incorporating factors such as poll quality, transparency, sample size, geographic indicators, and poll timing. By integrating these variables, our model seeks to provide a nuanced forecast that accounts for regional differences and methodological variations across polls, offering a comprehensive view of the projected support for each candidate.

Our findings suggest a competitive election landscape, with Harris showing strong prospects in key battleground states while Trump retains support in traditional Republican strongholds. These projections underscore the enduring influence of geographic voting patterns and the impact of polling methodology on electoral forecasting. The study provides valuable insights for political analysts, campaign strategists, and the public, contributing to a better understanding of how polling data can be utilized to anticipate electoral outcomes.

The remainder of this paper is organized as follows: @sec-data describes the dataset and the preprocessing steps involved in preparing data for the model. @sec-model explains the modeling approach, including the selection of predictors and the structure of the regression model. @sec-results presents the primary findings, highlighting state-by-state predictions and overall electoral projections. Section @sec-discussion discusses the implications, limitations, and future directions for this analysis. The Appendix section provides supplementary information on methodology, diagnostics, technical details of the model setup, acknowledgments, and references.


# Data {#sec-data}

## Overview

This study uses R packages [@citeR] to clean and analyz the dataset , including libraries from tidyverse [], ggplot2[].

After cleaning the data, which included grouping and removing missing values, the analysis dataset consists of 1,683 observations, focusing on the following 11 variables: pollster name, methodology, numeric grade, start date, end date, sample size, candidate name, percentage, transparency score, and population group. 

## Data Measurement and Considerations 

The dataset used in this analysis originates from FiveThirtyEight, a trusted source known for its rigorous methodology in collecting and aggregating polling data to represent public opinion accurately. To maintain data integrity and ensure a high standard of reliability, only polls meeting stringent quality criteria are included in the dataset. Specifically, each poll must disclose crucial information, including the pollsterâ€™s name, the exact dates of the survey, the sample size, and the full methodological details. These details encompass the polling medium (e.g., phone, online), use of verified voter files, demographic weighting criteria, and any adjustments applied to reflect a representative sample.

Polls are rigorously verified, and those that do not meet these requirements are excluded from the dataset. For instance, polls categorized as nonscientific, those that merge data from multiple unrelated sources, and those conducted by hobbyists or unverified entities are filtered out to prevent data quality compromise.

Once deemed credible, polls are incorporated into the FiveThirtyEight database. These polls then contribute to polling averages, forecast models, and political coverage, which depend heavily on the quality and reliability of public opinion data. This meticulous selection process ensures that the dataset captures a comprehensive and nuanced view of public sentiment, providing an accurate reflection of behavioral trends and preferences over time.

## Outcome Variable

The outcome variable of interest for this research is the percentage, representing the level of public support for Donald Trump. The distribution in @fig-pct indicates that most observations cluster around a support percentage of approximately 48%, suggesting moderate backing from the electorate. Additionally, a smaller proportion of polls show support exceeding 55%, indicating that while Trump has a core base, many voters remain either indifferent or opposed to him.

```{r}
#| label: fig-pct
#| fig-cap: Distribution of Support (percent) for Donald Trump
#| echo: false
#| warning: false
#| message: false
ggplot(analysis_data, aes(x = percent)) +
  geom_histogram(binwidth = 2, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Support (percent) for Donald Trump", x = "Support Percentage (percent)", y = "Count") +
  theme_minimal()
```

## Predictor Variables

### Numeric Grade

The numeric grade reflects the quality of the pollster, with FiveThirtyEight defining a scale from 0 to 3. A grade of 0 indicates a low-quality poll, while a grade of 3 signifies a high-quality pollster. After filtering for pollsters with a numeric grade higher than 2.5, we identified a total of 30 distinct pollsters, with half of them scoring between 2.6 and 2.8, as shown in @fig-numeric-grade .

```{r}
#| label: fig-numeric-grade
#| fig-cap: Distribution of Numeric Grades (2.6 to 3.0)
#| echo: false
#| warning: false
#| message: false

summary_data <- analysis_data %>%
    distinct(pollster_rating_name, .keep_all = TRUE) %>%
    group_by(numeric_grade) %>%
    summarise(count = n())

ggplot(analysis_data %>% distinct(pollster_rating_name, .keep_all = TRUE), 
       aes(x = numeric_grade)) + 
    geom_histogram(binwidth = 0.1, fill = "green", color = "black", alpha = 0.7) + 
    scale_x_continuous(breaks = seq(2.5, 3.0, by = 0.1)) + 
    scale_y_continuous(breaks = seq(0, max(summary_data$count), by = 1)) + 
    labs(title = "Distribution of Numeric Grades (2.6 to 3.0)", 
         x = "Numeric Grade", 
         y = "Count of Distinct Polls") + 
    theme_minimal()
```
### Sample Size

The sample size indicates the number of respondents in each poll. The distribution in @fig-sample-size exhibits a right-skewed shape, suggesting that there are more observations with smaller sample sizes compared to larger ones. The peak of the distribution is around 1,000, indicating that this is the most common sample size used in the polls. Overall, the sample size data highlights that each poll contains a sufficient number of respondents to provide reliable insights.

```{r}
#| label: fig-sample-size
#| fig-cap: Distribution of Sample Size
#| echo: false
#| warning: false
#| message: false

ggplot(analysis_data %>% filter(sample_size < 3000), aes(x = sample_size)) +
  geom_histogram(binwidth = 100, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Sample Size", x = "Sample Size", y = "Count") +
  theme_minimal()
```
### Transparency Score

The Transparency Score measures how transparent a pollster is, calculated based on the amount of information disclosed about its polls, weighted by recency. The highest possible score is 10, while the lowest is 0. The distribution of Transparency Scores for the filtered pollsters shows a peak around 9 as presented in @fig-transparency-score, indicating that this is the most common score. This suggests that among the selected pollsters, there is a predominance of high transparency scores.

```{r}
#| label: fig-transparency-score
#| fig-cap: Distribution of Transparency Score
#| echo: false
#| warning: false
#| message: false

ggplot(analysis_data %>% 
         distinct(pollster_rating_name, .keep_all = TRUE), 
       aes(x = transparency_score)) + 
  geom_histogram(binwidth = 1, fill = "green", color = "black", alpha = 0.7) + 
  scale_x_continuous(breaks = 3:10) +
  scale_y_continuous(breaks = seq(0, max(summary_data$count), by = 1)) +  
  labs(title = "Distribution of Transparency Score", x = "Transparency Score", y = "Count of Distinct Polls") + 
  theme_minimal()
```

### Days Until Election

The **days until election** represents the remaining time leading up to the final election day. As shown in the figure, the support percentage for Donald Trump fluctuated over time, with a slightly downward trend as the election approached, as indicated by the dashed trend line. This suggests that while public opinion varied significantly, there was a decrease in support as election day approached. This trend highlights the importance of monitoring real-time polling data, as sentiment may shift in the critical months leading up to a closely contested election.

```{r}
#| label: fig-end-date
#| fig-cap: Trend of Support Percentage for Donald Trump Over Days Until Election. Fluctuations in support levels are observed as the election approaches, with a slight downward trend indicated by the dashed curve.
#| echo: false
#| warning: false
#| message: false

ggplot(analysis_data, aes(x = days_until_election, y = percent)) + 
  geom_line(color = "skyblue", size = 1.2) +  
  geom_smooth(method = "loess", color = "pink", linetype = "dashed", size = 1) +  
  labs(x = "Days Until Election", y = "Support Percentage") + 
  theme_minimal(base_size = 14) +  
  theme(
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),  #
    axis.title.x = element_text(margin = margin(t = 10)),  
    axis.title.y = element_text(margin = margin(r = 10)),  
    axis.text = element_text(color = "#555555"),  
    panel.grid.minor = element_blank()  )
```

# Model {#sec-model}

To model Donald Trumpâ€™s polling percentages over time, we used a multiple linear regression framework, which estimates the relationship between polling percentages and various predictors by fitting a linear equation to the data. Analyzing the coefficients allows us to quantify the impact of each predictor on Trumpâ€™s polling percentages, while also assessing the overall fit of the model for reliable predictions.

To prevent overfitting, we applied a train-test data split. The training data is used to build the model, enabling it to learn patterns and relationships within the data. The test data, which the model has not seen before, serves to evaluate its performance on new, unseen data. This separation ensures that the model captures patterns that will generalize beyond the training dataset, rather than just memorizing it.

Below, we briefly describe the multiple linear regression model used to examine Trumpâ€™s winning probability. Additional details and model diagnostics are provided in [Appendix -@sec-model-details].

## Multiple Linear Regression Model Overview
The model now predicts Trumpâ€™s polling percentage (percent) using the following predictors:

- Numeric Grade (numeric_grade): Reflects the quality rating of the pollster.
- Sample Size (sample_size): The number of respondents in the poll.
- State (state): A categorical variable for different U.S. states.
- Transparency Score (transparency_score): A measure of how transparent the polling data and methodology are.
- Days Until Election (days_until_election): The left days until the US election.

The model takes the form:

\begin{align}
\text{pct}_i &= \beta_0 + \beta_1 \cdot \text{numeric\_grade}_i + \beta_2 \cdot \text{transparency\_score}_i \\
             &\quad + \beta_3 \cdot \text{sample\_size}_i + \beta_4 \cdot \text{state}_i + \beta_5 \cdot \text{days\_until\_election}_i + \epsilon_i \\
\epsilon_i &\sim \text{Normal}(0, \sigma^2)
\end{align}

Where: 
\begin{align}
\beta_0 & \text{ is the intercept term} \\
\beta_1, \beta_2, \beta_3, \beta_4, \beta_5 & \text{ are the coefficients for each predictor} \\
\sigma^2 & \text{ is the variance of the error term}
\end{align}

## Interpretation of Coefficients

- Intercept ($\beta_0$): This is the predicted Trump polling percentage when all predictors (numeric grade, sample size, state, transparency score, and end date) are at their baseline or zero value.
- Numeric Grade ($\beta_1$): This coefficient measures how much Trumpâ€™s polling percentage changes as the pollsterâ€™s numeric grade increases. A positive and significant coefficient would indicate that higher-rated pollsters report better polling numbers for Trump, while a negative coefficient would suggest the opposite.
- Sample Size ($\beta_2$): This measures the impact of the number of respondents on Trumpâ€™s polling percentage. A positive coefficient would indicate that larger sample sizes are associated with higher polling percentages for Trump.
- State ($\beta_3$): The coefficients for the state variable represent differences in Trumpâ€™s polling percentage in each state compared to the reference state (baseline category). For example, if the coefficient for Florida is negative, it means Trump polls lower in Florida compared to the reference state. The state-level effects account for regional differences in Trumpâ€™s support. Some states may show significantly higher or lower levels of support, even after adjusting for the time of the poll and pollster quality.
- Transparency Score ($\beta_4$): This coefficient shows how much Trumpâ€™s polling percentage is affected by the transparency of the poll. A positive coefficient would indicate that polls with higher transparency tend to report higher polling percentages for Trump, whereas a negative coefficient would imply the opposite.
- Days Until Election ($\beta_5$): The counting down days is a time-related variable. A positive and significant coefficient would suggest that Trumpâ€™s polling percentage has increased as the election date approaches, while a negative coefficient would suggest a decrease in his polling numbers over time.The coefficient for end_date informs us about how Trumpâ€™s polling percentages have evolved over time. A positive coefficient would suggest an upward trend, while a negative coefficient would indicate a decline.


## Model Justification
Based on the model summary shown in @tbl-summary-model, we observe that several state-level coefficients are statistically significant, indicating regional variations in support for Trump. Additionally, the coefficients for `transparency_score` and `days_until_election` are both highly significant, suggesting that pollster quality and the timing of the polls have notable effects on Trumpâ€™s polling percentages. A negative coefficient for `days_until_election` suggests a slight decline in support as the election approaches.

When evaluated on the test set, the model appears to struggle with accurately identifying Trump supporters, possibly due to unobserved factors or limitations in capturing the complexity of voter behavior.

The rationale for applying multiple regression in this context is to control for various influential factors simultaneouslyâ€”such as time trends (`days_until_election`), pollster quality (`transparency_score`), and regional differences (`state-level effects`). This approach allows us to isolate the individual impact of each variable, providing a more detailed understanding of how each factor contributes to Trumpâ€™s polling outcomes. The full coefficient output is shown in the [Appendix -@sec-model-details]

```{r}
#| echo: false
#| label: tbl-summary-model
#| tbl-cap: Regression Model Summary Table
#| warning: false
#| message: false

regression_model<-readRDS(here::here("models/regression_model.rds"))
summary<-summary(regression_model)
# Extract the coefficients to form a table
coefficients_table <- summary$coefficients

# Display the first 10 rows of the coefficients table using kable, formatted to 2 decimal places
kable(head(coefficients_table, 10), digits = 2)
```


# Results {#sec-results}

## Predicted Electoral Outcomes
We applied a regression model to predict the percentage of votes Trump is expected to receive in each state. The model results, combined with each state's electoral vote allocation, allowed us to predict the winner in each state. Based on this, we calculated the total number of electoral votes for both Trump and Harris.

The table below (@tbl-prediction) summarizes the predicted results, showing Trumpâ€™s predicted percentage, the number of electoral votes in each state, and the predicted winner (either Trump or Harris). For instance:
- Alabama: Trump is predicted to win 53% of the vote, securing all 9 electoral votes.
- California: Trump is predicted to receive 34.39% of the vote, resulting in a victory for Harris, who takes California's 55 electoral votes.
- Florida: The model predicts a close race, with Trump at 48.89% of the vote, resulting in a Harris win in this critical battleground state.

```{r}
#| echo: false
#| label: tbl-prediction
#| tbl-cap: Prediction for Trump and Harris by Electoral College
#| warning: false
#| message: false

# Read the test data from the .parquet file
analysis_data_test <- read_parquet(here::here("data/02-analysis_data/test_data.parquet"))
analysis_data_train<- read_parquet(here::here("data/02-analysis_data/train_data.parquet"))
# Filter out states in the test data that don't exist in the training data
analysis_data_test <- analysis_data_test %>%
 filter(state %in% unique(analysis_data_train$state))

# Define electoral votes for each state
electoral_votes <- data.frame(
  state = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida",
            "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", 
            "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", 
            "Missouri", "Montana", "Nebraska", "Nevada", 
            "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", 
            "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", 
            "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming", 
            "District of Columbia"),
  electoral_votes = c(9, 3, 11, 6, 54, 10, 7, 3, 30, 16, 4, 4, 20, 11, 6, 6, 8, 8, 4, 10, 11, 15, 10, 6, 10, 
                      4, 5, 6, 4, 14, 5, 28, 16, 3, 17, 7, 6, 19, 4, 9, 3, 11, 40, 6, 3, 13, 12, 5, 10, 3, 3))

# Apply the regression model to predict Trump's percentage in each state
analysis_data_test$predicted_percent_trump <- predict(regression_model, newdata = analysis_data_test)

# Summarize Trump's predicted percentage for each state
total_trump <- aggregate(predicted_percent_trump ~ state, data = analysis_data_test, FUN = mean)

# Combine electoral vote data with Trump's predictions
state_predictions <- merge(total_trump, electoral_votes, by = "state")

# Determine the winner for each state based on Trumpâ€™s predicted percentage
state_predictions$winner <- ifelse(state_predictions$predicted_percent_trump > 50, "Trump", "Harris")

# Calculate the electoral votes for each candidate
state_predictions$trump_electoral_votes <- ifelse(state_predictions$winner == "Trump", state_predictions$electoral_votes, 0)
state_predictions$harris_electoral_votes <- ifelse(state_predictions$winner == "Harris", state_predictions$electoral_votes, 0)

# Summarize total electoral votes for each candidate
trump_electoral_votes <- sum(state_predictions$trump_electoral_votes)
harris_electoral_votes <- sum(state_predictions$harris_electoral_votes)

# Create the table using kable
kable(state_predictions[, c("state", "predicted_percent_trump", "electoral_votes", "winner")], 
      col.names = c("State", "Trump Predicted %", "Electoral Votes", "Winner"), 
      digits = 2)
```


## Predicted Electoral Outcomes by State
The following table (@tbl-missing) serves as a supplement to the predicted outcomes, filling in the gaps for states where the model couldnâ€™t provide predictions. It allows for a complete view of electoral projections by assigning a likely outcome in each missing state based on historical data. This approach ensures every state is accounted for in the final electoral vote totals.

```{r}
#| echo: false
#| label: tbl-missing
#| tbl-cap: Missing States with Predicted Winner Based on Historical Lean
#| warning: false
#| message: false
# Create the data frame with missing states, electoral votes, and predicted winner based on historical lean
missing_states <- data.frame(
  state = c("Alabama", "Alaska", "Arkansas", "Connecticut", "Delaware", "Hawaii", "Idaho", 
            "Illinois", "Indiana", "Kansas", "Kentucky", "Louisiana", "Mississippi", "North Dakota", 
            "Oklahoma", "Oregon", "South Carolina", "Tennessee", "Utah", "Washington", 
            "West Virginia", "Wyoming", "District of Columbia"),
  Electoral_Votes = c(9, 3, 6, 7, 3, 4, 4, 19, 11, 6, 8, 8, 6, 3, 7, 8, 9, 11, 6, 12, 4, 3, 3),
  Prediction_Based_on_Historical_Lean = c("Trump", "Trump", "Trump", "Harris", "Harris", 
                                          "Harris", "Trump", "Harris", "Trump", "Trump", 
                                          "Trump", "Trump", "Trump", "Trump", "Trump", 
                                          "Harris", "Trump", "Trump", "Trump", "Harris", 
                                          "Trump", "Trump", "Harris")
)

# Display the table with kable
kable(missing_states, col.names = c("State", "Electoral Votes", "Prediction Based on Historical Lean"))
```


The following map (@fig-statemap) shows the predicted winner for each state in the 2024 U.S. Presidential Election, based on the regression model's predicted vote percentages for Trump and Harris. The predicted outcome in the regression model reflects the geographic voting patterns, with Trump winning in traditionally Republican-leaning states like Alabama, Missouri, and Wyoming, while Harris dominates in Democratic strongholds such as California, New York, and Illinois. However, key battleground states such as Florida and Arizona are predicted to favor Harris, potentially determining the overall election outcome.

```{r fig-statemap}
#| echo: false
#| label: fig-statemap
#| tbl-cap: Predicted Winner of 2024 US Presidential Election by State
#| warning: false
#| message: false

state_predictions <- merge(state_predictions, missing_states, by = "state", all = TRUE)

state_predictions <- state_predictions %>%
  mutate(
    trump_electoral_votes = case_when(
      is.na(Prediction_Based_on_Historical_Lean) ~ trump_electoral_votes,  # Keep original if NA
      Prediction_Based_on_Historical_Lean == "Trump" ~ Electoral_Votes,    # Assign Electoral_Votes if "Trump"
      TRUE ~ 0  # Set to 0 otherwise
    ),
    harris_electoral_votes = case_when(
      is.na(Prediction_Based_on_Historical_Lean) ~ harris_electoral_votes,  # Keep original if NA
      Prediction_Based_on_Historical_Lean == "Harris" ~ Electoral_Votes,    # Assign Electoral_Votes if "Harris"
      TRUE ~ 0  # Set to 0 otherwise
    )
  )

# Replace NA values in the 'winner' column with historical lean predictions for missing states
state_predictions$winner <- ifelse(
  is.na(state_predictions$winner),
  state_predictions$Prediction_Based_on_Historical_Lean,
  state_predictions$winner
)

# Assign colors based on the updated 'winner' column
state_predictions$winner_color <- ifelse(state_predictions$winner == "Trump", "red", "blue")

# Create a map visualization showing the predicted winner by state
plot_usmap(data = state_predictions, values = "winner_color", regions = "states") +
  scale_fill_manual(values = c("red" = "red", "blue" = "blue"), 
                    name = "Predicted Winner", labels = c("Harris", "Trump")) +
  labs(title = "Predicted Winner of the 2024 U.S. Presidential Election by State") +
  theme(legend.position = "right")

```



The table below (@tbl-numstate) shows the numerical predicted winner of the 2024 US Presidential Election by state. Harris is expected to win the 2024 U.S. Presidential Election, securing 387 electoral votes, compared to Trumpâ€™s 151 electoral votes. The election outcome hinges on several battleground states, where the vote margins are predicted to be narrow.
```{r}
#| echo: false
#| label: tbl-numstate
#| tbl-cap: Numerical Predicted Winner of 2024 US Presidential Election by State
#| warning: false
#| message: false

trump_total <- sum(state_predictions$trump_electoral_votes, na.rm = TRUE)
harris_total <- sum(state_predictions$harris_electoral_votes, na.rm = TRUE)

# Create a summary data frame
summary_df <- data.frame(
  Candidate = c("Trump", "Harris"),
  Total_Electoral_Votes = c(trump_total, harris_total)
)

# Display the summary table in kable format
kable(summary_df, col.names = c("Candidate", "Total Electoral Votes"), format = "markdown")
```



# Discussion {#sec-discussion}

## Overview of Predictive Modeling for the 2024 U.S. Election
This paper employs a regression model to forecast the 2024 U.S. Presidential Election outcomes between Kamala Harris and Donald Trump. By analyzing historical state-level voting data, we estimated Trumpâ€™s vote percentages across states and calculated each candidateâ€™s projected electoral votes. Our model predicts a significant victory for Harris, who is projected to secure 387 electoral votes compared to Trumpâ€™s 151. This finding underscores the impact of demographic and geographic factors on the U.S. electoral landscape. A geographic visualization further emphasizes the anticipated state-by-state outcomes and reveals enduring regional voting patterns.

## Regional Voting Patterns and Their Impact on Electoral Outcomes
Our analysis demonstrates the persistence of geographic voting patterns in U.S. elections. As expected, traditional Democratic strongholds such as California, New York, and Illinois favor Harris, while Republican-dominated states like Alabama and Wyoming show support for Trump. These regional preferences align with historical voting behaviors, suggesting that party loyalty and demographic factors continue to shape election results.

The model also highlights the critical role of battleground states, with states such as Florida and Arizona predicted to lean toward Harris. The influence of these states, where margins are often narrow, emphasizes the importance of campaign efforts and voter mobilization in these regions. The projections illustrate that minor shifts in voter sentiment within these states could decisively impact the overall election outcome.

## Polling and Electoral Uncertainty
The modelâ€™s reliance on historical polling data and state-level predictions reflects certain limitations inherent in election forecasting. For example, while the model captures general trends, it does not account for potential turnout variations, third-party candidates, or unexpected political events that might affect voter behavior. Furthermore, the use of polling data presents a challenge due to its variability; certain states with less frequent polling data show broader confidence intervals, indicating greater uncertainty in those regions.

This variability suggests that further studies could benefit from integrating real-time data and employing Bayesian methodologies to account for evolving voter preferences. Such an approach could improve the accuracy of predictions, especially in regions with historically unpredictable outcomes. Future research may also consider factors like demographic shifts and economic conditions, which could significantly influence voter preferences over time.

## Implications for Future Electoral Modeling
The findings from this analysis underscore the need for a nuanced approach to election forecasting. While historical voting patterns provide a solid foundation, they may not fully capture the complexities of modern elections, where factors such as social media influence and voter sentiment play increasingly prominent roles. Incorporating these additional variables, particularly in battleground states, could refine the modelâ€™s predictive power and provide a more comprehensive understanding of the electoral landscape.

For future iterations, we recommend expanding the model to include demographic data, such as age, education level, and income, which could reveal deeper insights into voter behavior. Additionally, real-time polling updates could offer a dynamic perspective, allowing the model to adapt to changes in public opinion as the election date approaches. Employing these enhancements would improve model reliability, particularly in closely contested states where the margin of error can significantly impact the final prediction.

## Weakness
Despite the model's strengths, it has limitations that requires further exploration. The assumption of linear relationships between predictors may oversimplify complex voter behaviors and social influences. The dataset simplifies the potentioanl influecne behind the US election. Additionally, the reliance on past data assumes that historical trends will persist, which may not hold true in the rapidly shifting political climate of the U.S. To address these issues, future models could benefit from incorporating voter turnout projections and real-time sentiment analysis, potentially drawing data from social media platforms and news sources to gauge public opinion. Moreover, a comparative post-election analysis could offer valuable insights, revealing areas where the model succeeded and where it may need refinement. This iterative approach would help create a more resilient and adaptable electoral forecasting model.

\newpage

\appendix

# Appendix {-}

# Pollster Methodology Overview and Evaluation

## Overview of SurveyUSA

SurveyUSA is a privately held opinion research company that operates nationwide, across all 50 U.S. states. Since its founding, the company has conducted over 40,000 research projects, serving a client base of 400 organizations, including media outlets, corporations, non-profits, government agencies, and academic institutions. Known for its expertise in localized opinion research, SurveyUSA focuses on gathering data at the city, county, and regional levels. The company offers timely, cost-effective surveys tailored to meet specific client needs, distinguishing itself from larger global firms.


## Population, Frame, and Sample

* Target Population: U.S. citizens eligible to vote in the 2024 presidential election.\
* Sample Frame:  U.S. households with either home telephones or access to devices such as phones or tablets. \
* Sample Size: Sample sizes vary across different polls. For the 2024 U.S. presidential election cycle, SurveyUSA conducted 49 polls, with sample sizes ranging from 507 to 2,330 for registered voters or likely voters. The average sample size for these polls is approximately 1,045 households.\

## Recruitment

SurveyUSA employs a mixed-method approach to recruitment, including online panels, telephone calls, and a text-to-web method. Some respondents are recruited through Random Digit Dialing (RDD) using telephone samples purchased from Aristotle, while others, who do not use home telephones, are invited to complete the survey on an electronic device such as a phone or tablet. Respondents from non-probability online panels are selected randomly by Cint/Lucid Holdings LLC.\

## Sampling approach and Trade-offs

SurveyUSA uses a blend of probability and non-probability sampling methods. Some respondents are drawn from non-probability online panels, while others are recruited using probability-based telephone sampling. Responses are weighted based on the latest U.S. Census estimates for age, gender, ethnicity, and region, ensuring alignment with the target population. Questions and answer choices are rotated to reduce order bias, recency effects, and latency effects.\

* **Advantages:**

The diverse sampling approach not only ensures a broad range of opinions is captured but also complements probability-based sampling, which accurately reflects the overall population. Furthermore, reweighting the data according to U.S. Census demographics strengthens the credibility of the results by ensuring demographic accuracy. Additionally, rotating questions and answer choices helps mitigate bias, further improving the reliability of the data. Finally, the use of online surveys offers a cost-effective solution for efficient data collection.\
* **Disadvantages:**

Phone-based data collection tends to be time-consuming and can be affected by interviewer effects during telephone interviews. Additionally, challenges like non-response issues, such as busy signals or refusals to participate, can hinder the effectiveness of the data collection process.\

## Non-response Handling

In cases of non-response, SurveyUSA attempts follow-up calls if interviews are interrupted by answering machines or busy signals. Weighting is applied to adjust for non-response bias, although this doesn't completely eliminate challenges posed by unreachable or unwilling participants.\

## Questionnaire Evaluation


* **Positive Aspects:**
A logical flow between questions facilitates easy navigation for respondents throughout the survey, while simple wording promotes inclusivity by enabling individuals from diverse backgrounds to comprehend the questions. Furthermore, all questions are directly relevant to analyzing the 2024 U.S. presidential election, and providing predefined response options simplifies the choices for participants.\
* **Negative Aspects:**
Static options for party affiliation and ideology may fail to capture the nuances of respondentsâ€™ political beliefs. These rigid categories could oversimplify complex political identities.\

## Summary Evaluation

SurveyUSAâ€™s methodology reflects a balanced approach, leveraging various sampling approach and method to reach a representative sample. While its blend of probability and non-probability methods has strengths, such as cost-effectiveness and broad reach, it faces challenges related to telephone interview logistics, potential interviewer bias, and the limitations of fixed questionnaire options. Nevertheless, the inclusion of data weighting and question rotation adds credibility to its results, making SurveyUSA a reliable pollster for localized opinion research. 



# Idealized Methodology and Survey


## Objective and Overview
The goal of this survey methodology is to accurately forecast the outcome of the U.S. presidential election by collecting high-quality, representative data from a diverse set of respondents across the country. With a budget of \$100,000, this methodology incorporates sophisticated sampling techniques, robust respondent recruitment strategies, and rigorous data validation protocols. The approach is designed to maximize accuracy, reduce bias, and account for various demographic, geographic, and political factors that influence voting behavior.

## Core Objectives
* Obtain a representative sample of the U.S. electorate.
* Ensure data quality through rigorous validation.
* Leverage statistical modeling and poll aggregation for an accurate prediction.

## Sampling Strategy
The sampling strategy is designed to ensure that the survey reaches a broad, representative section of the voting population. To achieve this, we will use **stratified random sampling** combined with **quota sampling** for key demographics. This ensures that each important subgroup within the population is adequately represented.

### Stratification Variables
* **Age Groups**: 18-29, 30-44, 45-64, 65+ 
* **Gender**: Male, Female, Non-binary/Other 
* **Race/Ethnicity**: White, Black, Hispanic/Latino, Asian, Indigenous, Other 
* **Education Level**: No high school, High school graduate, College graduate, Post-graduate 
* **Income Bracket**: <$30,000, \$30,000-\$60,000, \$60,000-\$100,000, >\$100,000 
* **Geographic Region**: Northeast, Midwest, South, West 

### Sample Size
A total of **10,000 respondents** will be surveyed, providing a margin of error of approximately Â±1\% at a 95\% confidence level. This sample size will allow for detailed subgroup analysis (e.g., by state, demographic group), yielding statistically robust predictions.

### Weighting
Post-stratification weights will be applied to adjust for any oversampling or undersampling of specific demographic groups. For example, younger voters or underrepresented minorities will be weighted to reflect their true proportions in the voting population.

## Recruitment Strategy
To maximize respondent diversity and ensure accurate sampling, the survey will employ **multi-channel recruitment**:

* **Digital Advertisements**: Targeted ads on platforms like Facebook, Instagram, and Google will recruit respondents based on their demographic profiles (age, gender, location, political interest).
* **Email Outreach**: If permissible, voter registration databases will be accessed to send email invitations to registered voters.
* **Partnerships with Civic Organizations**: Partnering with non-profits and civic organizations that engage diverse communities will further boost respondent diversity.
* **Incentives**: Each participant will be entered into a lottery with a chance to win a \$100 gift card to encourage participation.


## Data Validation and Quality Assurance
Maintaining data integrity and ensuring high-quality responses are critical to the accuracy of the election forecast. Several measures will be put in place to validate responses and reduce noise in the dataset.

### Data Validation Protocols
* **Real-time Captcha Verification**: This will prevent automated bots from submitting responses.
* **Email/Phone Verification**: Respondents will verify their email or phone number to ensure authenticity and prevent duplicate submissions.
* **Time on Task Monitoring**: The survey platform will monitor the time respondents spend on each question. Responses completed suspiciously quickly will be flagged for review.
* **Voter Registration Cross-Check**: If feasible, respondents will be cross-referenced with voter registration records to ensure eligibility.
* **Response Audits**: Randomly selected respondents will be contacted to verify the accuracy of their responses, ensuring dataset integrity.

## Poll Aggregation and Data Analysis
### Poll Aggregation
This survey will be combined with results from reputable polling firms (e.g., YouGov, Ipsos, Gallup) to strengthen the forecast through a **poll-of-polls** approach.

* **Weighting by Methodology and Recency**: Poll results will be weighted based on the rigor of their methodology and the recency of the poll.
* **Handling Bias and Variability**: Aggregated results will adjust for pollster biases and variability between polls to ensure that no single poll dominates the prediction.

### Modeling Approach
**Bayesian hierarchical models** will account for variability across different states, demographics, and regions. This will allow for modeling the popular vote and potentially translating it into **Electoral College predictions**.

## Budget Allocation
* **Respondent Recruitment (Targeted ads, outreach)**: \$70,000
* **Incentives (e.g., lottery prizes)**: \$10,000
* **Survey Platform (Google Forms, Qualtrics subscription)**: \$5,000
* **Data Validation Tools**: \$5,000
* **Poll Aggregation \& Analysis Software**: \$10,000

---

## Survey Implementation
The survey will be implemented via **Google Forms**, which offers a cost-effective platform for data collection. You can access the survey at the following link: [Google Form Survey](https://forms.gle/XxtMTMc45d6VzNuy8)

### **Survey Structure**

\begingroup
\small
**Introduction**:

Thank you for taking part in this survey aimed at predicting the outcome of the 2024 US Presidential election. Your insights are valuable to our research.

Please note:

- **All responses will be kept strictly confidential.**
- **Your participation is entirely voluntary.**
- **We kindly request that you answer all questions honestly and to the best of your knowledge.**
- **The survey is estimated to take approximately 10 minutes to complete.**

If you have any inquiries or concerns regarding this survey, please don't hesitate to contact the research team at [shaw.wei@mail.utoronto.ca](mailto:shaw.wei@mail.utoronto.ca).(Yuxuan Wei, Xuanle Zhou, Yongqi Liu)

Your contribution to this study is greatly appreciated! Each participant will be entered into a lottery with a chance to win a $100 gift card!

**Section 1: Eligibility Screening**:

Are you a U.S. citizen?
- Yes
- No [If No, end survey]

Will you be 18 or older by Election Day (November 5, 2024)?
- Yes
- No [If No, end survey]

Are you registered to vote in the United States?
- Yes
- No
- Not sure
- Plan to register before the election

**Section 2: Demographic Information**:

What is your age group?
- 18-29
- 30-44
- 45-64
- 65 or older
- Prefer not to say

What is your gender?
- Male
- Female
- Non-binary/Other
- Prefer not to say

What is your race/ethnicity? (Select all that apply)
- White
- Black or African American
- Hispanic or Latino
- Asian
- American Indian or Alaska Native
- Native Hawaiian or Pacific Islander
- Prefer not to say
- Other: [Short text answer]

What is your highest level of education completed?
- No high school
- High school graduate or equivalent
- Some college, no degree
- Bachelor's degree
- Graduate or professional degree
- Prefer not to say

What was your total household income in 2023?
- Less than $30,000
- $30,000 - $59,999
- $60,000 - $99,999
- $100,000 - $149,999
- $150,000 or more
- Prefer not to say

In which region of the United States do you currently reside?
- Northeast (ME, NH, VT, MA, RI, CT, NY, NJ, PA)
- Midwest (OH, IN, IL, MI, WI, MN, IA, MO, ND, SD, NE, KS)
- South (DE, MD, DC, VA, WV, NC, SC, GA, FL, KY, TN, AL, MS, AR, LA, OK, TX)
- West (MT, ID, WY, CO, NM, AZ, UT, NV, WA, OR, CA, AK, HI)

**Section 3: Political Views and Voting Intentions**:

How likely are you to vote in the 2024 Presidential election?
- Definitely will vote
- Probably will vote
- Might or might not vote
- Probably will not vote
- Definitely will not vote

Generally speaking, do you usually think of yourself as a:
- Democrat
- Republican
- Independent
- Prefer not to say
- Other: [Short text answer]

If the 2024 Presidential election were held today, who would you vote for?
- Kamala Harris (Democrat)
- Donald Trump (Republican)
- Undecided
- Prefer not to say
- Other: [Short text answer]

How certain are you about your choice?
- Very certain
- Somewhat certain
- Not very certain
- Not at all certain
- Prefer not to say

Which THREE issues are most important to you in deciding your vote? (Select exactly three)
- Economy and jobs
- Healthcare
- Immigration
- Climate change
- National security
- Education
- Gun policy
- Social justice/racial equality
- Taxes
- Crime and public safety
- Foreign policy
- Other: [Short text answer]

**Section 4: Information Sources and Engagement**:

What is your primary source of political news? (Select all that apply)
- Network TV news (ABC, CBS, NBC)
- Cable TV news (CNN, Fox News, MSNBC)
- News websites
- Social media
- Radio
- Print newspapers
- Friends and family
- Other: [Short text answer]

How closely have you been following news about the 2024 Presidential election?
- Very closely
- Somewhat closely
- Not too closely
- Not at all
- Not sure

**Section 5: Validation and Consent**:

Please verify that you are a human by selecting "Blue" from the following options:
- Red
- Green
- Blue
- Yellow

Consent Statement:
"I understand that my participation in this survey is voluntary and that my responses will be kept confidential. I agree that my responses may be used for research purposes."
- Yes, I agree
- No, I do not agree

Email Address: [Email field]

**End Message**:

"Thank you for completing this survey. Your response has been recorded.
If you have any questions about this survey or would like to be informed about the results, please contact at [shaw.wei@mail.utoronto.ca](mailto:shaw.wei@mail.utoronto.ca)."

\endgroup
    
---

## Survey Design Considerations
* **Question Wording**: All questions are designed to avoid bias or leading responses.
* **Neutrality**: Political questions are framed neutrally to avoid influencing respondents' answers.
* **Pilot Testing**: The survey will undergo a pilot test to identify and resolve any issues before full deployment.

# Model details {#sec-model-details}

## Diagnostics

```{r}
#| echo: false
#| label: fig-diagnosis-1
#| tbl-cap: Linear regression assumptions hold.
#| warning: false
#| message: false
#| fig.width: 10
#| fig.height: 8

par(mfrow = c(2, 2))  
plot(regression_model)
```

## Calculate Mean Squared Error and Mean Absolute Error on Test Data
```{r}
#| echo: false
#| label: fig-diagnosis-2
#| tbl-cap: Calculate Mean Squared Error (MSE) on Test Data
#| warning: false
#| message: false

# Predicted and actual values
predicted_values <- predict(regression_model, newdata = analysis_data_test)
actual_values <- analysis_data_test$percent

# Calculate Mean Squared Error (MSE)
mse <- mean((predicted_values - actual_values)^2)

# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predicted_values - actual_values))

# Calculate R-squared
ss_total <- sum((actual_values - mean(actual_values))^2)
ss_residual <- sum((predicted_values - actual_values)^2)
r_squared <- 1 - (ss_residual / ss_total)

# Combine metrics into a data frame for display
metrics_df <- data.frame(
  Metric = c("Mean Squared Error (MSE)", "Mean Absolute Error (MAE)", "R-squared"),
  Value = c(mse, mae, r_squared))

# Display the metrics table using kable
kable(metrics_df)
```

## Model Summary
```{r}
#| echo: false
#| tbl-cap: Complete Model Coefficient Summary Table
#| warning: false
#| message: false

# Get summary of the regression model
model_summary <- summary(regression_model)

# Extract and convert the coefficients summary to a data frame
coefficients_df <- as.data.frame(model_summary$coefficients)
colnames(coefficients_df) <- c("Estimate", "Std. Error", "t value", "Pr(>|t|)")

# Extract additional statistics
r_squared <- model_summary$r.squared
adj_r_squared <- model_summary$adj.r.squared
f_statistic <- model_summary$fstatistic[1]
p_value <- pf(f_statistic, model_summary$fstatistic[2], model_summary$fstatistic[3], lower.tail = FALSE)
residual_se <- model_summary$sigma

# Create a data frame for additional statistics with consistent column names
additional_stats <- data.frame(
  Estimate = c(r_squared, adj_r_squared, f_statistic, p_value, residual_se),
  `Std. Error` = NA,
  `t value` = NA,
  `Pr(>|t|)` = NA,
  row.names = c("R-squared", "Adjusted R-squared", "F-statistic", "F-statistic p-value", "Residual Std. Error")
)

# Ensure column names are identical between data frames
colnames(additional_stats) <- colnames(coefficients_df)

# Combine the coefficients and additional statistics
full_summary_df <- rbind(coefficients_df, additional_stats)

# Display the full summary table using kable
kable(full_summary_df)
```

## Multicollinearity Check on the Training Data
```{r}
#| echo: false
#| fig-cap: Correlation Matrix of "Numeric Grade", "Sample Size", "Transparency Score"and "Days Until Election"
#| warning: false
#| message: false

# Calculate the correlation matrix
cor_matrix <- cor(analysis_data_train[, c("numeric_grade", "sample_size", "transparency_score", "days_until_election")], use = "complete.obs")

# Rename the row and column names of the correlation matrix to remove underscores
colnames(cor_matrix) <- gsub("_", " ", colnames(cor_matrix))
rownames(cor_matrix) <- gsub("_", " ", rownames(cor_matrix))

# Create a beautiful correlation plot with modified labels
corrplot(
  cor_matrix, 
  method = "color",      
  type = "upper",        
  addCoef.col = "black", 
  tl.col = "black",      
  tl.srt = 45,          
  number.cex = 0.8,      
  col = colorRampPalette(c("red", "white", "blue"))(200) )

```

\newpage

# Acknowledgements
@citeR
Thanks to Open AI and ChatGPT 4.0 is used to write the analysis of the paper.

@fivethirty provides the data. @tidyverse, @ggplot, @knitr


# References